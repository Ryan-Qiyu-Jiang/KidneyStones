{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abcd_experiments.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN1DNUswYdjn5HPZLkv5exx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryan-Qiyu-Jiang/KidneyStones/blob/master/abcd_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJkMKaEYjPhd"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Ryan-Qiyu-Jiang/rloss.git\n",
        "%cd /content/rloss/\n",
        "!git checkout color_query"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/rloss/data/VOC2012/\n",
        "!./fetchVOC2012.sh\n",
        "%cd /content/rloss/data/pascal_scribble/\n",
        "! ./fetchPascalScribble.sh"
      ],
      "metadata": {
        "id": "x4-ND59tjZ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/rloss/pytorch/wrapper/bilateralfilter\n",
        "!apt-get install swig -y\n",
        "!swig -python -c++ bilateralfilter.i\n",
        "!python setup.py install"
      ],
      "metadata": {
        "id": "_6atZyvZoVyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq tensorboardX\n",
        "!pip install -qqq wandb\n",
        "!pip install -qqq pytorch-lightning\n",
        "# !pip install -qqq kornia\n",
        "!pip install -qqq higher"
      ],
      "metadata": {
        "id": "ovWMQ0j9jgy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/rloss/pytorch/pytorch_deeplab_v3_plus "
      ],
      "metadata": {
        "id": "J8WVxn2-1KZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from mypath import Path\n",
        "from dataloaders import make_data_loader\n",
        "from dataloaders.custom_transforms import denormalizeimage\n",
        "from modeling.sync_batchnorm.replicate import patch_replication_callback\n",
        "from modeling.deeplab import *\n",
        "from utils.loss import SegmentationLosses\n",
        "from utils.calculate_weights import calculate_weigths_labels\n",
        "from utils.lr_scheduler import LR_Scheduler\n",
        "from utils.saver import Saver\n",
        "from utils.summaries import TensorboardSummary\n",
        "from utils.metrics import Evaluator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torch.nn import functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torch import nn\n",
        "import torch\n",
        "from argparse import Namespace\n",
        "from dataloaders.utils import decode_seg_map_sequence\n",
        "\n",
        "from color_query import BaseModel, get_args, SingleDataset, RepeatDataset, DeepLabEncoder, BaseColorModel\n",
        "\n",
        "segmentation_classes = [\n",
        "    'background','aeroplane','bicycle','bird','boat','bottle',\n",
        "    'bus','car','cat','chair','cow','diningtable','dog','horse',\n",
        "    'motorbike','person','pottedplant','sheep','sofa','train','tvmonitor'\n",
        "]\n",
        "\n",
        "def labels():\n",
        "  l = {}\n",
        "  for i, label in enumerate(segmentation_classes):\n",
        "    l[i] = label\n",
        "  return l\n",
        "\n",
        "def wb_mask(bg_img, pred_mask, true_mask):\n",
        "  return wandb.Image(bg_img, masks={\n",
        "    \"prediction\" : {\"mask_data\" : pred_mask, \"class_labels\" : labels()},\n",
        "    \"ground truth\" : {\"mask_data\" : true_mask, \"class_labels\" : labels()}})"
      ],
      "metadata": {
        "id": "O5uQZJxtrSoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "from dataloaders import make_data_loader\n",
        "\n",
        "args_dict = get_args()\n",
        "args_dict['cuda'] = True\n",
        "args_dict['checkname'] = 'ignore'\n",
        "args_dict['epochs'] = 1\n",
        "args_dict['shuffle'] = False # True for real training\n",
        "args_dict['batch_size'] = 10\n",
        "args_dict['lr'] = 1e-2\n",
        "args_dict['inner_lr'] = 1e-2\n",
        "args_dict['test_steps'] = 50\n",
        "args_dict['full_gt'] = True # True for gt\n",
        "args_dict['limit_dataset'] = False\n",
        "# args_dict['rloss_scale'] = 1\n",
        "args = Namespace(**args_dict)\n",
        "\n",
        "kwargs = {'num_workers': 6, 'pin_memory': True}\n",
        "train_loader, val_loader, test_loader, nclass = make_data_loader(args, **kwargs)\n",
        "gt_loader = val_loader\n",
        "\n",
        "seeds_args = Namespace(**dict(args_dict, full_gt=False) )\n",
        "seeds_loader, _, _, _ = make_data_loader(seeds_args, **kwargs)"
      ],
      "metadata": {
        "id": "XdbQ5byZrK2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QCzehcPFU6-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "batch = iter(seeds_loader).next()\n",
        "batch_sample = {k:v for k,v in batch.items()}\n",
        "\n",
        "# w = 513\n",
        "# circle = torch.zeros((3, w, w))\n",
        "# gt = torch.zeros((w,w)).long()\n",
        "# gt[:,:] = 0 #255\n",
        "\n",
        "# for y in range(w):\n",
        "#   for x in range(w):\n",
        "#     if ( (y-w/2)**2 + (x-w/2)**2 ) < (w//3)**2:\n",
        "#       circle[:,y,x] = 1.\n",
        "#       # gt[y,x] = 1\n",
        "\n",
        "# # gt[:40, :40] = 0\n",
        "# # gt[w//2-25:w//2+25, w//2-25:w//2+25] = 1\n",
        "# gt[:w//2,:] = 1\n",
        "# circle.to(batch['image'].device)\n",
        "# gt.to(batch['label'].device)\n",
        "\n",
        "i = 5\n",
        "# 0 plane\n",
        "# 5 sheep\n",
        "single_sample = {\n",
        "    'image': [batch['image'][i]] * len(batch['image']),\n",
        "    'label': [batch['label'][i]] * len(batch['label'])\n",
        "}\n",
        "# batch['image'][i]\n",
        "# batch['label'][i]\n",
        "\n",
        "# batch_sample = single_sample # for single image overfit\n",
        "bs = 5\n",
        "single_dataset = RepeatDataset(batch_sample,  100*10)\n",
        "single_train_loader = DataLoader(single_dataset, batch_size=bs, shuffle=True, num_workers=4)\n",
        "single_dataset = RepeatDataset(batch_sample, 10)\n",
        "single_val_loader = DataLoader(single_dataset, batch_size=bs, shuffle=False, num_workers=4)\n",
        "\n",
        "plt.imshow(batch_sample['image'][0].numpy().transpose(1,2,0));"
      ],
      "metadata": {
        "id": "KIeBG7-htBlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elementwise_entropy(logits=None, probs=None):\n",
        "  assert(not (logits is None and probs is None) ), \"entropy() is missing input\"\n",
        "  eps = 1e-16\n",
        "\n",
        "  probs = nn.Softmax(dim=1)(logits) if logits is not None else probs\n",
        "\n",
        "  bs, num_class, h, w = probs.shape\n",
        "  entropy = -(probs* (probs + eps).log()).sum(1)\n",
        "  return entropy\n",
        "\n",
        "def visualize_entropy(logits, return_img=False):\n",
        "  logits = logits[0].unsqueeze(0) # pick first example\n",
        "  entropy = elementwise_entropy(logits).detach().cpu()[0]\n",
        "  wb_img = wandb.Image(entropy, caption=f\"mean entropy={entropy.mean():9.4f}\")\n",
        "  if return_img:\n",
        "    return wb_img\n",
        "  wandb.log({'train/entropy_map': wb_img}, commit=False)\n",
        "\n",
        "def visualize_c_entropy(logits, x):\n",
        "  logits = logits[0].unsqueeze(0) # pick first example\n",
        "  x = x[0].unsqueeze(0)\n",
        "  probs = nn.Softmax(dim=1)(logits)\n",
        "  c_entropy = compute_conditional_entropy(probs, x).detach().cpu()[0]\n",
        "  wb_img = wandb.Image(c_entropy, caption=f\"mean conditional entropy={c_entropy.mean():9.4f}\")\n",
        "  wandb.log({'train/conditional_entropy_map': wb_img}, commit=False)\n",
        "\n",
        "def visualize_local_mi():\n",
        "  wb_img = wandb.Image(last_patch_mi[0], caption=f\"mean local MI={last_patch_mi.mean():9.4f}\")\n",
        "  wandb.log({'train/local_mi_map': wb_img}, commit=False)\n",
        "\n",
        "def visualize_global_mi():\n",
        "  wb_img = wandb.Image(last_global_mi[0], caption=f\"mean global MI={last_global_mi.mean():9.4f}\")\n",
        "  wandb.log({'train/global_mi_map': wb_img}, commit=False)\n",
        "\n",
        "def yuv(x):\n",
        "  T = torch.tensor( [[ 0.299,     0.587,    0.114],\n",
        "                     [-0.14713,  -0.28886,  0.436],\n",
        "                     [0.615,    -0.51499, -0.10001],\n",
        "                     ]\n",
        "                   , device=x.device)\n",
        "  return torch.einsum(\"cc, bchw -> bchw\", T, x)\n",
        "\n",
        "def mutual_info(logits, x):\n",
        "  \"\"\"MI(X,Y) = H(Y) - H(Y|X) = entropy(average(p_y)) - average(entropy(p_y|x))\"\"\"\n",
        "  r = 4\n",
        "  logits = F.interpolate(logits, size=(x.size(2)//r, x.size(3)//r), mode='bilinear', align_corners=True)\n",
        "  x = F.interpolate(x, size=(x.size(2)//r, x.size(3)//r), mode='bilinear', align_corners=True)\n",
        "  # import pdb;pdb.set_trace()\n",
        "\n",
        "  eps = 1e-16\n",
        "  bs, num_classes, h, w = logits.shape\n",
        "\n",
        "  probs = nn.Softmax(dim=1)(logits)\n",
        "\n",
        "  p_avg = probs.reshape(bs, num_classes,-1).mean(dim=-1)\n",
        "  HY = -(p_avg* (p_avg + eps).log()).sum(dim=-1)\n",
        "  # HYX = elementwise_entropy(probs=probs).reshape(bs,-1).mean(dim=-1)\n",
        "  HYX = compute_conditional_entropy2(probs, x).reshape(bs,-1).mean(dim=-1) #(-(probs* (probs + eps).log()).sum(1)).reshape(bs,-1).mean(dim=-1)\n",
        "  return (HY-HYX).mean()\n",
        "\n",
        "def compute_conditional_entropy(probs, x):\n",
        "  eps = 1e-16\n",
        "  bs, num_classes, h, w = probs.shape\n",
        "  _, in_channels, _, _ = x.shape\n",
        "\n",
        "  probs = probs.reshape(bs, num_classes, -1)\n",
        "  # entropy = -(probs* (probs + eps).log()).sum(1) # bs, num_pixels\n",
        "  x = yuv(x)\n",
        "  x = x.reshape(bs, in_channels, -1)\n",
        "  \n",
        "  result = torch.zeros((bs, h*w), device=x.device)\n",
        "  for i in range(x.size(-1)):\n",
        "    q = x[:,:,i]\n",
        "    atten = -(x-q.unsqueeze(-1)).abs().sum(1)\n",
        "    # atten = torch.einsum(\"bcn, bc -> bn\", x, q) # do better than dot product\n",
        "    atten = (atten-atten.mean(dim=-1, keepdim=True))*100\n",
        "    atten = nn.functional.softmax(atten, dim=-1)\n",
        "  \n",
        "    p_avg  = torch.einsum(\"bcn, bn -> bc\", probs, atten)\n",
        "    ce = -(p_avg* (p_avg + eps).log()).sum(-1)\n",
        "    result[:, i] = ce\n",
        "  return result.reshape(bs, h, w)\n",
        "\n",
        "def compute_conditional_entropy2(probs, x):\n",
        "  eps = 1e-16\n",
        "  bs, num_classes, h, w = probs.shape\n",
        "  _, in_channels, _, _ = x.shape\n",
        "\n",
        "  probs = probs.reshape(bs, num_classes, -1)\n",
        "  x = yuv(x)\n",
        "  x = x.reshape(bs, in_channels, -1)\n",
        "  \n",
        "  # atten = torch.einsum(\"bcm, bcn -> bmn\", x, x)\n",
        "  _x = x.permute(0,2,1)\n",
        "  atten = -torch.cdist( _x, _x, p=2 )\n",
        "  atten -= atten.mean(dim=-1, keepdim=True)\n",
        "  atten *= 5\n",
        "  atten = nn.functional.softmax(atten, dim=-1)\n",
        "  values = torch.einsum(\"bmn, bkn -> bkm\", atten, probs)\n",
        "  conditional_entropy = -(values* (values + eps).log()).sum(1)\n",
        "  return conditional_entropy.reshape(bs, h, w)\n",
        "\n",
        "\n",
        "last_patch_mi = None\n",
        "last_global_mi = None\n",
        "\n",
        "def MI(logits, x, bias=1., r=1, return_map=False):\n",
        "  \"\"\"MI(X,Y) = H(Y) - H(Y|X) = entropy(average(p_y)) - average(entropy(p_y|x))\"\"\"\n",
        "  eps = 1e-16\n",
        "  bs, num_classes, h, w = logits.shape\n",
        "  probs = nn.Softmax(dim=1)(logits)\n",
        "\n",
        "  p_avg = probs.reshape(bs, num_classes,-1).mean(dim=-1)\n",
        "  HY = -(p_avg* (p_avg + eps).log()).sum(dim=-1)\n",
        "\n",
        "  if r > 1:\n",
        "    logits = F.interpolate(logits, size=(h//r, w//r), mode='bilinear', align_corners=True)\n",
        "    probs = nn.Softmax(dim=1)(logits)\n",
        "    x = F.interpolate(x, size=(h//r, w//r), mode='bilinear', align_corners=True)\n",
        "    HYX = compute_conditional_entropy2(probs, x)\n",
        "    HYX = F.interpolate(HYX.unsqueeze(1), size=(h, w), mode='bilinear', align_corners=True)\n",
        "  else:\n",
        "    HYX = compute_conditional_entropy2(probs, x)\n",
        "\n",
        "  if return_map:\n",
        "    global last_global_mi\n",
        "    last_global_mi = HYX.detach().cpu()\n",
        "\n",
        "  HYX = HYX.reshape(bs,-1).mean(dim=-1)\n",
        "  return bias*HY-HYX\n",
        "\n",
        "\n",
        "def MI_efficient(logits, x, local_weight=0.5, local_bias=1, local_reduction=5):\n",
        "  \"\"\"MI estimation is quadratic in respect to number of pixels due to self attention.\n",
        "  If the image is hxw, global MI estimation takes O(h^2 w^2) time and memory.\n",
        "  This MI estimator downsamples the image and estimates coarse MI,\n",
        "  as well as local MI on image patches.\n",
        "  \"\"\"\n",
        "\n",
        "  patch_size = 50\n",
        "  bs, num_classes, h, w = logits.shape\n",
        "  _, in_channels, _, _ = x.shape\n",
        "  r = h//patch_size\n",
        "\n",
        "  coarse_logits = F.interpolate(logits, size=(h//r, w//r), mode='bilinear', align_corners=True)\n",
        "  coarse_x = F.interpolate(x, size=(h//r, w//r), mode='bilinear', align_corners=True)\n",
        "  coarse_global_mi = MI(coarse_logits, coarse_x, return_map=True).mean()\n",
        "\n",
        "  patch_mi = torch.zeros((bs, h//patch_size, w//patch_size), device=x.device)\n",
        "  for r in range(h//patch_size):\n",
        "    for c in range(w//patch_size):\n",
        "      R = r*patch_size\n",
        "      C = c*patch_size\n",
        "      logit_patch = logits[:,:,R:R+patch_size, C:C+patch_size]\n",
        "      x_patch = x[:,:,R:R+patch_size, C:C+patch_size]\n",
        "      patch_mi[:,r,c] = MI(logit_patch, x_patch, bias=local_bias, r=local_reduction)\n",
        "\n",
        "  global last_patch_mi, last_global_mi\n",
        "  last_patch_mi = patch_mi.detach().cpu()\n",
        "\n",
        "  local_mi = patch_mi.mean()\n",
        "  return (1-local_weight)*coarse_global_mi + local_weight*local_mi\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hchM-9hMD8um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "C &= \\{ c_p| p \\in \\Omega \\}\\ \\text{grid of label probabilities} \\\\\n",
        "X &= \\{ x_p| p \\in \\Omega \\} \\ \\text{image colors} \\\\\n",
        "c_p &= \\text{label rv for some point} \\\\\n",
        "x_p &= \\text{color rv for some point} \\\\\n",
        "I(c_p|x_p) &= H(c_p) - H(c_p|x_p) \\\\\n",
        "I(c_p|x_p)\\ &\\tilde{=}\\ H(\\overline{C}) - \\overline{H(C\\ \\text{softmax} (\\ norm(X X^T) ) )} \\\\ \n",
        "\\end{aligned}\n",
        "$$"
      ],
      "metadata": {
        "id": "X-GKGS3_dYoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from DenseCRFLoss import DenseCRFLoss\n",
        "\n",
        "class SegModelDebug(BaseModel):\n",
        "    def __init__(self, hparams, model=None):\n",
        "        super().__init__(hparams)\n",
        "        self.model = DeepLab(num_classes=self.hparams.nclass,\n",
        "                            backbone=self.hparams.backbone,\n",
        "                            output_stride=self.hparams.out_stride,\n",
        "                            sync_bn=self.hparams.sync_bn,\n",
        "                            freeze_bn=self.hparams.freeze_bn)\n",
        "        # self.densecrflosslayer = DenseCRFLoss(weight=1, sigma_rgb=self.hparams.sigma_rgb, sigma_xy=self.hparams.sigma_xy, scale_factor=self.hparams.rloss_scale)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "    \n",
        "    def get_loss(self, batch, batch_idx):\n",
        "            i = batch_idx\n",
        "            epoch = self.current_epoch\n",
        "            image, target = batch['image'], batch['label']\n",
        "            target[target==254]=255\n",
        "            self.scheduler(self.optimizer, i, epoch, self.best_pred)\n",
        "            output = self.forward(image)\n",
        "\n",
        "            celoss = self.criterion(output, target.long())\n",
        "\n",
        "            denormalized_image = denormalizeimage(image, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "            croppings = (target!=254).float() if target is not None else torch.ones((image.size(0), image.size(2), image.size(3))).to(self.device)\n",
        "            probs = nn.Softmax(dim=1)(output)\n",
        "            # r_loss = self.hparams.densecrfloss*self.densecrflosslayer(denormalized_image, probs, croppings).to(self.device)\n",
        "            r_loss = -MI_efficient(output, image, local_weight=self.hparams.mi_local_weight, local_bias=self.hparams.mi_local_bias)\n",
        "\n",
        "            if i % 10 == 0:\n",
        "              with torch.no_grad():\n",
        "                mask = torch.max(output[0].unsqueeze(0),1)[1].detach()\n",
        "                visualize_entropy(output)\n",
        "                # visualize_c_entropy(output, image)\n",
        "                visualize_global_mi()\n",
        "                visualize_local_mi()\n",
        "                self.logger.experiment.log({'train/img': wb_mask(image[0].cpu().numpy().transpose([1,2,0]), mask[0].cpu().numpy(), target[0].cpu().numpy())}, commit=False) \n",
        "\n",
        "            self.log('train/ce', celoss.item())\n",
        "            self.log('train/-MI', r_loss.item())\n",
        "            self.log('train/entropy', elementwise_entropy(probs=probs).mean().item())\n",
        "            return celoss + 2*r_loss #if epoch == 0 else 2*r_loss\n",
        "    \n",
        "    def get_loss_val(self, batch, batch_idx):\n",
        "            # self.model.train()\n",
        "            image, target = batch['image'], batch['label']\n",
        "            target[target==254]=255\n",
        "            i= batch_idx % len(batch['image'])\n",
        "            output = self.forward(image)\n",
        "            celoss = self.criterion(output, target.long())\n",
        "            for i in range(len(batch['image'])):\n",
        "              mask = torch.max(output[i].unsqueeze(0),1)[1].detach()\n",
        "              self.val_img_logs += [wb_mask(image[i].cpu().numpy().transpose([1,2,0]), mask[0].cpu().numpy(), target[i].cpu().numpy()), visualize_entropy(output[i].unsqueeze(0), return_img=True)]\n",
        "\n",
        "            # denormalized_image = denormalizeimage(image, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "            croppings = (target!=254).float() if target is not None else torch.ones((image.size(0), image.size(2), image.size(3))).to(self.device)\n",
        "            probs = nn.Softmax(dim=1)(output)\n",
        "            # r_loss = self.hparams.densecrfloss*self.densecrflosslayer(denormalized_image, probs, croppings)\n",
        "            r_loss = -mutual_info(output, image)\n",
        "            \n",
        "            pred = output.data.cpu().numpy()\n",
        "            pred = np.argmax(pred, axis=1)\n",
        "            target = target.cpu().numpy()\n",
        "            self.evaluator.add_batch(target, pred)\n",
        "            result = {\n",
        "              'ce_loss': celoss,\n",
        "              'r_loss': r_loss,\n",
        "            }\n",
        "            return result\n",
        "\n",
        "    def validation_summary(self, outputs):\n",
        "      test_loss = 0.0\n",
        "      masks = self.val_img_logs\n",
        "      self.val_img_logs = []\n",
        "      for output in outputs:\n",
        "        test_loss += output['ce_loss']\n",
        "\n",
        "      # Fast test during the training\n",
        "      Acc = self.evaluator.Pixel_Accuracy()\n",
        "      Acc_class = self.evaluator.Pixel_Accuracy_Class()\n",
        "      mIoU = self.evaluator.Mean_Intersection_over_Union()\n",
        "      FWIoU = self.evaluator.Frequency_Weighted_Intersection_over_Union()\n",
        "      # if len(masks)>10:\n",
        "      self.logger.experiment.log({'val/Examples':masks[:50]}, commit=False)\n",
        "      self.logger.experiment.log({'val/mIoU': mIoU}, commit=False)\n",
        "      self.logger.experiment.log({'val/Acc': Acc}, commit=False)\n",
        "      self.logger.experiment.log({'val/Acc_class': Acc_class}, commit=False)\n",
        "      self.logger.experiment.log({'val/fwIoU': FWIoU}, commit=False)\n",
        "      self.logger.experiment.log({'val/loss_epoch': test_loss.item()})\n",
        "      print('Validation:')\n",
        "      print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(Acc, Acc_class, mIoU, FWIoU))\n",
        "      print('Loss: %.3f' % test_loss)\n",
        "      self.evaluator.reset()\n",
        "\n",
        "    def get_10x_lr_params(self):\n",
        "        modules = [self.model.decoder, self.model.aspp, self.coarse_cls]\n",
        "        for i in range(len(modules)):\n",
        "            for m in modules[i].named_modules():\n",
        "                if isinstance(m[1], nn.Conv2d) or isinstance(m[1], SynchronizedBatchNorm2d) \\\n",
        "                        or isinstance(m[1], nn.BatchNorm2d):\n",
        "                    for p in m[1].parameters():\n",
        "                        if p.requires_grad:\n",
        "                            yield p"
      ],
      "metadata": {
        "id": "RWK4Jg0oEbd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "eOxoX-Xb03LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.batch_size = 5\n",
        "args.limit_dataset = False\n",
        "args.nclass = nclass\n",
        "args.lr = 1e-2\n",
        "args.inner_lr = 1e-2\n",
        "args.densecrfloss = 2e-9\n",
        "args.epochs = 5\n",
        "args.mi_local_weight = 0.5\n",
        "args.mi_local_bias = 0.5\n",
        "# args.backbone = \"efficientnet\"\n",
        "# args.backbone = \"mobilenet\"\n",
        "# train_loader, val_loader, test_loader, nclanss = make_data_loader(args, **kwargs)\n",
        "train_loader, val_loader = single_train_loader, single_val_loader\n",
        "\n",
        "args.num_img_tr=len(train_loader)\n",
        "model = SegModelDebug(args)\n",
        "# model = SegModelDebug(args)\n",
        "# model.configure_optimizers()\n",
        "# for param in model.encoder.model.backbone.parameters():\n",
        "#   param.requires_grad = False\n",
        "\n",
        "wandb_logger = WandbLogger(project='Color-Query', name='seeds_batch_efficient_mi') # proto_dlv3_rand-space  deeplabv3+_seeds  prototype_aspp_seeds  deeplabv3+_color-low-feats\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=args.epochs, logger=wandb_logger, log_every_n_steps=10, num_sanity_val_steps=0, progress_bar_refresh_rate=0, accumulate_grad_batches=2)\n",
        "results = trainer.fit(model, train_loader, val_loader)\n",
        "wandb.finish()\n",
        "\n",
        "# plt.imshow(atten[0].reshape(128,128).cpu().numpy());plt.pause(1)\n",
        "# plt.imshow((mi[0] > 2.8792).detach().cpu().numpy());plt.pause(1)\n",
        "# (mi[0][mi[0] > 2.8792]).mean()"
      ],
      "metadata": {
        "id": "NfYLmnEQz8ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(atten[0,0].reshape(h,w).detach().cpu().numpy());plt.pause(1)\n",
        "\n",
        "# import gc\n",
        "# for obj in gc.get_objects():\n",
        "#     try:\n",
        "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
        "#             print(type(obj), obj.size())\n",
        "#     except:\n",
        "#         pass"
      ],
      "metadata": {
        "id": "TUQSe-yj1Nzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dXZDsraULULp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}